# Kitesurf Equipment Scraper & Analyzer

Sistema automatizado para scraping de grupos do Facebook de equipamentos de kitesurfe e anÃ¡lise inteligente com OpenAI.

## ğŸ“‹ Funcionalidades

- **Scraping HistÃ³rico**: Busca posts dos Ãºltimos 2 anos (execuÃ§Ã£o Ãºnica)
- **Scraping Incremental**: Busca posts das Ãºltimas 12 horas (2x por dia)
- **AnÃ¡lise Inteligente**: Usa GPT-4 Vision para analisar texto, imagens e comentÃ¡rios
- **ExtraÃ§Ã£o Estruturada**: Identifica anÃºncios e extrai dados estruturados

## ğŸ—‚ï¸ Estrutura do Projeto

```
kitesurf-scraper/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ groups.json           # Lista de grupos do Facebook
â”‚   â””â”€â”€ .env                   # VariÃ¡veis de ambiente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ apify_scraper.py      # Cliente Apify
â”‚   â”œâ”€â”€ openai_analyzer.py    # AnÃ¡lise com OpenAI
â”‚   â”œâ”€â”€ data_processor.py     # Processamento de dados
â”‚   â””â”€â”€ models.py             # Schemas de dados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_historical.py     # Script para scraping histÃ³rico
â”‚   â”œâ”€â”€ run_incremental.py    # Script para scraping incremental
â”‚   â””â”€â”€ schedule_jobs.sh      # Agendamento com cron
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados brutos do Apify
â”‚   â”œâ”€â”€ processed/            # Dados processados
â”‚   â””â”€â”€ analyzed/             # AnÃ¡lises da OpenAI
â””â”€â”€ logs/                     # Logs de execuÃ§Ã£o
```

## ğŸš€ Setup

### 1. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Configurar variÃ¡veis de ambiente

Crie o arquivo `config/.env`:

```env
APIFY_API_TOKEN=seu_token_apify
OPENAI_API_KEY=sua_chave_openai
OPENAI_MODEL=gpt-4o-mini  # ou gpt-4o para melhor qualidade
```

### 3. Configurar grupos do Facebook

Edite `config/groups.json` com os grupos desejados.

## ğŸ“Š Uso

### Scraping HistÃ³rico (2 anos)

```bash
python scripts/run_historical.py
```

### Scraping Incremental (Ãºltimas 12 horas)

```bash
python scripts/run_incremental.py
```

### Agendar execuÃ§Ãµes automÃ¡ticas

```bash
# Adicionar ao crontab
# Executa Ã s 8h e 20h todos os dias
0 8,20 * * * /path/to/scripts/run_incremental.py
```

## ğŸ“¦ Dados ExtraÃ­dos

Para cada anÃºncio, o sistema extrai:

- âœ… **is_advertisement**: Se Ã© realmente um anÃºncio
- ğŸ·ï¸ **brand**: Marca do equipamento (Duotone, North, Cabrinha, etc)
- ğŸ“¦ **model**: Modelo especÃ­fico
- ğŸ“… **year**: Ano do equipamento
- ğŸ’° **price**: PreÃ§o em reais
- ğŸ“ **city**: Cidade do anÃºncio
- ğŸ—ºï¸ **state**: Estado (sigla)
- ğŸ”§ **has_repair**: Se tem reparos
- ğŸ·ï¸ **equipment_type**: Tipo (kite, board, bar, harness, etc)
- ğŸ“ **size**: Tamanho (para kites e pranchas)
- ğŸ†• **condition**: Estado (novo, usado, etc)
- ğŸ“ **additional_items**: Itens adicionais incluÃ­dos
- ğŸ“± **contact_info**: InformaÃ§Ãµes de contato

## ğŸ¤– Como Funciona

1. **Apify** faz scraping dos posts dos grupos
2. Sistema baixa imagens dos posts
3. **GPT-4 Vision** analisa:
   - Texto do post
   - Imagens anexadas
   - ComentÃ¡rios relevantes
4. Dados estruturados sÃ£o salvos em JSON/CSV

## ğŸ“ˆ Monitoramento

Logs sÃ£o salvos em `logs/` com formato:
- `historical_YYYY-MM-DD.log`
- `incremental_YYYY-MM-DD_HH-MM.log`
